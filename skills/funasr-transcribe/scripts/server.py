#!/usr/bin/env python3
# -*- encoding: utf-8 -*-
"""
FunASR è½¬å½•æœåŠ¡ - HTTP API æœåŠ¡å™¨ï¼ˆFastAPIç‰ˆï¼‰
å¯åŠ¨æœ¬åœ° ASR æœåŠ¡ï¼Œæä¾›éŸ³é¢‘/è§†é¢‘è½¬å½•åŠŸèƒ½
æ”¯æŒè‡ªåŠ¨å¯åŠ¨å’Œç©ºé—²è‡ªåŠ¨å…³é—­ï¼ˆ10åˆ†é’Ÿï¼‰
"""

import os
import sys
import json
import signal
import time
from datetime import datetime
from pathlib import Path
from typing import Optional
import argparse
import threading
from pathlib import Path

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•å’Œ skill æ ¹ç›®å½•
SCRIPT_DIR = Path(__file__).parent.absolute()
SKILL_DIR = SCRIPT_DIR.parent
MODELS_CONFIG = SKILL_DIR / "assets" / "models.json"

# å…¨å±€æœåŠ¡çŠ¶æ€
SERVICE_PID = os.getpid()
SERVICE_START_TIME = time.time()
LAST_ACTIVITY_TIME = time.time()
IDLE_TIMEOUT = 600  # 10åˆ†é’Ÿï¼ˆ600ç§’ï¼‰
SERVICE_RUNNING = True
MONITOR_THREAD = None


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
    errors = []

    try:
        import fastapi
    except ImportError:
        errors.append("FastAPI")

    try:
        import funasr
    except ImportError:
        errors.append("FunASR")

    try:
        import torch
    except ImportError:
        errors.append("PyTorch")

    return errors


def get_model_cache_dir():
    """è·å– ModelScope æ¨¡å‹ç¼“å­˜ç›®å½•"""
    cache_dir = os.environ.get('MODELSCOPE_CACHE', os.path.expanduser('~/.cache/modelscope/hub'))
    return Path(cache_dir) / "models"


def check_model_exists(model_id: str) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
    cache_dir = get_model_cache_dir()
    model_path = cache_dir / model_id.replace('/', os.sep)
    return model_path.exists() and any(model_path.iterdir())


def check_models():
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
    if not MODELS_CONFIG.exists():
        return ["æ¨¡å‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"]

    with open(MODELS_CONFIG, 'r', encoding='utf-8') as f:
        config = json.load(f)

    missing = []
    for model in config.get('models', []):
        if model.get('required', True):
            if not check_model_exists(model['id']):
                missing.append(model.get('name', model['id']))

    return missing


def startup_check():
    """å¯åŠ¨å‰æ£€æŸ¥"""
    print("ğŸ” å¯åŠ¨å‰æ£€æŸ¥...")

    # æ£€æŸ¥ä¾èµ–
    missing_deps = check_dependencies()
    if missing_deps:
        print(f"\nâŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
        print(f"\nè¯·å…ˆè¿è¡Œå®‰è£…è„šæœ¬:")
        print(f"  python {SKILL_DIR / 'scripts' / 'setup.py'}")
        return False

    # æ£€æŸ¥æ¨¡å‹
    missing_models = check_models()
    if missing_models:
        print(f"\nâŒ ç¼ºå°‘æ¨¡å‹: {', '.join(missing_models)}")
        print(f"\nè¯·å…ˆè¿è¡Œå®‰è£…è„šæœ¬ä¸‹è½½æ¨¡å‹:")
        print(f"  python {SKILL_DIR / 'scripts' / 'setup.py'}")
        return False

    print("âœ… æ£€æŸ¥é€šè¿‡\n")
    return True


def update_activity():
    """æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´"""
    global LAST_ACTIVITY_TIME
    LAST_ACTIVITY_TIME = time.time()


def get_idle_time() -> int:
    """è·å–å½“å‰ç©ºé—²æ—¶é—´ï¼ˆç§’ï¼‰"""
    return int(time.time() - LAST_ACTIVITY_TIME)


def should_shutdown() -> bool:
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥å…³é—­æœåŠ¡"""
    idle_time = get_idle_time()
    return idle_time > IDLE_TIMEOUT


def shutdown_service():
    """å…³é—­æœåŠ¡"""
    global SERVICE_RUNNING
    print(f"\nğŸ• æœåŠ¡ç©ºé—²è¶…è¿‡ {IDLE_TIMEOUT // 60} åˆ†é’Ÿï¼Œè‡ªåŠ¨å…³é—­")
    SERVICE_RUNNING = False
    os.kill(SERVICE_PID, signal.SIGTERM)


def monitor_idle():
    """ç›‘æ§æœåŠ¡ç©ºé—²çŠ¶æ€çš„åå°çº¿ç¨‹"""
    global SERVICE_RUNNING

    while SERVICE_RUNNING:
        time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡

        # æ£€æŸ¥æ˜¯å¦æœ‰æ´»åŠ¨
        if get_idle_time() < 30:  # 30ç§’å†…æœ‰æ´»åŠ¨
            continue

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å…³é—­
        if should_shutdown():
            print(f"â° æœåŠ¡ç©ºé—²æ£€æµ‹: {get_idle_time()} ç§’ï¼Œè‡ªåŠ¨å…³é—­æœåŠ¡")
            shutdown_service()
            break


def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    global SERVICE_RUNNING
    print(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    SERVICE_RUNNING = False
    sys.exit(0)


# æ³¨å†Œä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)

# æ£€æŸ¥é€šè¿‡åå†å¯¼å…¥
if not startup_check():
    sys.exit(1)

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from funasr import AutoModel

app = FastAPI(title="FunASR Transcribe API", version="1.0.0")

# å…¨å±€æ¨¡å‹å®ä¾‹
model = None
model_with_spk = None

SUPPORTED_EXTENSIONS = {
    '.mp4', '.avi', '.mov', '.mkv', '.wmv', '.webm',  # è§†é¢‘
    '.mp3', '.wav', '.m4a', '.flac', '.aac', '.ogg', '.opus', '.wma', '.caf'  # éŸ³é¢‘
}


def init_model(with_speaker: bool = False):
    """åˆå§‹åŒ– ASR æ¨¡å‹"""
    global model, model_with_spk

    if with_speaker and model_with_spk is None:
        print("æ­£åœ¨åŠ è½½ ASR æ¨¡å‹ï¼ˆå«è¯´è¯äººåˆ†ç¦»ï¼‰...")
        # ä½¿ç”¨æ ‡å‡† ASR æ¨¡å‹ + CAM++ è¯´è¯äººåˆ†ç¦»æ¨¡å‹
        model_with_spk = AutoModel(
            model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
            punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
            spk_model="cam++",
            disable_update=True,
            disable_log=False,
        )
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼ˆå«è¯´è¯äººåˆ†ç¦»ï¼‰")
        return model_with_spk

    if model is None:
        print("æ­£åœ¨åŠ è½½ ASR æ¨¡å‹...")
        model = AutoModel(
            model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
            punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
            disable_update=True,
            disable_log=False,
        )
        print("æ¨¡å‹åŠ è½½å®Œæˆ")

    return model_with_spk if with_speaker else model


def format_timestamp(ms: int) -> str:
    """å°†æ¯«ç§’è½¬æ¢ä¸ºæ—¶é—´æˆ³æ ¼å¼

    è§„åˆ™ï¼š
    - å¦‚æœæœ‰å°æ—¶ï¼Œä½¿ç”¨ HH:MM:SS æ ¼å¼
    - å¦åˆ™ä½¿ç”¨ MM:SS æ ¼å¼ï¼ˆå‚è€ƒæ–‡ä»¶ä¸­çš„æ ¼å¼ï¼‰
    """
    seconds = ms // 1000
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60

    if hours > 0:
        # æœ‰å°æ—¶æ—¶æ˜¾ç¤º HH:MM:SS
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    else:
        # å¦åˆ™æ˜¾ç¤º MM:SS
        return f"{minutes:02d}:{secs:02d}"


def result_to_markdown(result: dict, filename: str, diarize: bool = False) -> str:
    """å°†è½¬å½•ç»“æœè½¬æ¢ä¸º Markdown æ ¼å¼"""
    md_lines = []

    # æ ‡é¢˜ï¼ˆä¸å¸¦è½¬å½•æ—¶é—´ï¼‰
    md_lines.append(f"# è½¬å½•ï¼š{filename}\n")
    md_lines.append("## è½¬å½•å†…å®¹\n")

    # å¤„ç†å¥å­ä¿¡æ¯
    if 'sentence_info' in result and result['sentence_info']:
        segments = result['sentence_info']

        # --- åˆå¹¶è¿ç»­ç›¸åŒè¯´è¯äººçš„æ®µè½ ---
        merged_segments = []
        current = None
        # é»˜è®¤æœ€å¤§åˆå¹¶æ—¶é•¿ 30 ç§’
        max_merge_ms = 30000

        for seg in segments:
            start_ms = seg.get('start', 0)
            text = seg.get('sentence', seg.get('text', ''))
            spk = seg.get('spk') if diarize else None

            if current is None:
                current = {
                    'start': start_ms,
                    'spk': spk,
                    'texts': [text],
                }
            else:
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆå¹¶ï¼šç›¸åŒè¯´è¯äººä¸”æ—¶é•¿ä¸è¶…è¿‡é™åˆ¶
                if spk == current.get('spk'):
                    if start_ms - current['start'] <= max_merge_ms:
                        # åˆå¹¶åˆ°å½“å‰æ®µè½
                        current['texts'].append(text)
                    else:
                        # è¶…è¿‡æ—¶é•¿é™åˆ¶ï¼Œè¾“å‡ºå½“å‰æ®µè½å¹¶å¼€å§‹æ–°æ®µè½
                        merged_segments.append(current)
                        current = {
                            'start': start_ms,
                            'spk': spk,
                            'texts': [text],
                        }
                else:
                    # è¯´è¯äººåˆ‡æ¢ï¼Œè¾“å‡ºå½“å‰æ®µè½å¹¶å¼€å§‹æ–°æ®µè½
                    merged_segments.append(current)
                    current = {
                        'start': start_ms,
                        'spk': spk,
                        'texts': [text],
                    }

        # è¾“å‡ºæœ€åä¸€ä¸ªæ®µè½
        if current is not None:
            merged_segments.append(current)

        # è§„èŒƒåŒ–è¯´è¯äºº IDï¼ˆä» 1 å¼€å§‹è¿ç»­ç¼–å·ï¼‰
        spk_map = {}
        next_label = 1
        for seg in merged_segments:
            spk = seg.get('spk')
            if spk is not None and spk not in spk_map:
                spk_map[spk] = next_label
                next_label += 1

        # è¾“å‡ºåˆå¹¶åçš„æ®µè½
        for seg in merged_segments:
            start_ts = format_timestamp(int(seg['start']))
            combined_text = ' '.join(seg['texts'])
            spk = seg.get('spk')

            if spk is not None:
                # æœ‰è¯´è¯äººä¿¡æ¯
                if isinstance(spk, str) and spk.startswith('speaker_'):
                    speaker_num = int(spk.split('_')[1]) + 1
                    speaker = f"å‘è¨€äºº{speaker_num}"
                else:
                    # ä½¿ç”¨æ˜ å°„åçš„ç¼–å·ï¼ˆæ”¯æŒæ•´æ•°ç±»å‹çš„ spkï¼‰
                    speaker = f"å‘è¨€äºº{spk_map.get(spk, 1)}"
                md_lines.append(f"{speaker} {start_ts}\n")
            else:
                # æ— è¯´è¯äººåˆ†ç¦»æ—¶ï¼Œåªæ˜¾ç¤ºæ—¶é—´æˆ³
                md_lines.append(f"{start_ts}\n")

            md_lines.append(f"{combined_text}\n\n")
    else:
        # ç®€å•æ–‡æœ¬è¾“å‡º - æ·»åŠ é»˜è®¤è¯´è¯äººæ ‡ç­¾å’Œæ—¶é—´æˆ³
        text = result.get('text', '')
        # å³ä½¿ä¸å¯ç”¨è¯´è¯äººåˆ†ç¦»ï¼Œä¹Ÿæ˜¾ç¤º"å‘è¨€äºº1"ä»¥ä¿æŒæ ¼å¼ä¸€è‡´
        md_lines.append(f"å‘è¨€äºº1 00:00\n")
        md_lines.append(f"{text}\n\n")

    return '\n'.join(md_lines)


# è¯·æ±‚æ¨¡å‹
class TranscribeRequest(BaseModel):
    file_path: str
    output_path: Optional[str] = None
    diarize: bool = False


class BatchTranscribeRequest(BaseModel):
    directory: str
    output_dir: Optional[str] = None
    diarize: bool = False


class TranscribeResponse(BaseModel):
    success: bool
    output_path: Optional[str] = None
    text: Optional[str] = None
    sentence_count: Optional[int] = None
    error: Optional[str] = None


class BatchTranscribeResponse(BaseModel):
    success: bool
    total: Optional[int] = None
    results: Optional[list] = None
    error: Optional[str] = None


class HealthResponse(BaseModel):
    status: str
    service: str
    uptime: int
    idle_time: int


@app.middleware("http")
async def update_activity_middleware(request: Request, call_next):
    """æ›´æ–°æ´»åŠ¨æ—¶é—´çš„ä¸­é—´ä»¶"""
    update_activity()
    response = await call_next(request)
    return response


@app.get("/health", response_model=HealthResponse)
async def health():
    """å¥åº·æ£€æŸ¥"""
    return HealthResponse(
        status="ok",
        service="FunASR Transcribe",
        uptime=int(time.time() - SERVICE_START_TIME),
        idle_time=get_idle_time()
    )


@app.post("/transcribe", response_model=TranscribeResponse)
async def transcribe(request: TranscribeRequest):
    """
    è½¬å½•éŸ³é¢‘/è§†é¢‘æ–‡ä»¶

    è¯·æ±‚å‚æ•°:
        - file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
        - output_path: è¾“å‡º Markdown æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        - diarize: æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»ï¼ˆå¯é€‰ï¼Œé»˜è®¤ falseï¼‰

    è¿”å›:
        - success: æ˜¯å¦æˆåŠŸ
        - output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        - text: è½¬å½•çš„çº¯æ–‡æœ¬
        - sentence_count: å¥å­æ•°é‡
        - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    """
    try:
        # æ›´æ–°æ´»åŠ¨æ—¶é—´
        update_activity()

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(request.file_path):
            raise HTTPException(
                status_code=400,
                detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {request.file_path}"
            )

        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        ext = Path(request.file_path).suffix.lower()
        if ext not in SUPPORTED_EXTENSIONS:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}ï¼Œæ”¯æŒçš„æ ¼å¼: {', '.join(SUPPORTED_EXTENSIONS)}"
            )

        # é»˜è®¤è¾“å‡ºè·¯å¾„
        output_path = request.output_path
        if not output_path:
            output_path = str(Path(request.file_path).with_suffix('.md'))

        # è·å–æ¨¡å‹
        current_model = init_model(with_speaker=request.diarize)

        print(f"æ­£åœ¨è½¬å½•: {request.file_path}")

        # æ‰§è¡Œè½¬å½•
        result = current_model.generate(input=request.file_path, cache={})

        # å¤„ç†ç»“æœ
        if isinstance(result, list) and len(result) > 0:
            result = result[0]

        # è½¬æ¢ä¸º Markdown
        filename = Path(request.file_path).name
        markdown_content = result_to_markdown(result, filename, request.diarize)

        # ä¿å­˜æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

        print(f"è½¬å½•å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {output_path}")

        return TranscribeResponse(
            success=True,
            output_path=output_path,
            text=result.get('text', ''),
            sentence_count=len(result.get('sentence_info', [])) if 'sentence_info' in result else 0
        )

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/batch_transcribe", response_model=BatchTranscribeResponse)
async def batch_transcribe(request: BatchTranscribeRequest):
    """
    æ‰¹é‡è½¬å½•ç›®å½•ä¸­çš„æ–‡ä»¶

    è¯·æ±‚å‚æ•°:
        - directory: ç›®å½•è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
        - output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤åŒç›®å½•ï¼‰
        - diarize: æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»ï¼ˆå¯é€‰ï¼Œé»˜è®¤ falseï¼‰
    """
    try:
        # æ›´æ–°æ´»åŠ¨æ—¶é—´
        update_activity()

        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.isdir(request.directory):
            raise HTTPException(
                status_code=400,
                detail=f"ç›®å½•ä¸å­˜åœ¨: {request.directory}"
            )

        output_dir = request.output_dir or request.directory

        # æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
        files = []
        for ext in SUPPORTED_EXTENSIONS:
            files.extend(Path(request.directory).glob(f'*{ext}'))
            files.extend(Path(request.directory).glob(f'*{ext.upper()}'))

        if not files:
            raise HTTPException(
                status_code=400,
                detail="ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„åª’ä½“æ–‡ä»¶"
            )

        results = []
        current_model = init_model(with_speaker=request.diarize)

        for file_path in files:
            try:
                print(f"æ­£åœ¨è½¬å½•: {file_path}")
                result = current_model.generate(input=str(file_path), cache={})

                if isinstance(result, list) and len(result) > 0:
                    result = result[0]

                output_path = Path(output_dir) / f"{file_path.stem}.md"
                markdown_content = result_to_markdown(result, file_path.name, request.diarize)

                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(markdown_content)

                results.append({
                    "file": str(file_path),
                    "output": str(output_path),
                    "success": True
                })
            except Exception as e:
                results.append({
                    "file": str(file_path),
                    "success": False,
                    "error": str(e)
                })

        return BatchTranscribeResponse(
            success=True,
            total=len(files),
            results=results
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def start_idle_monitor():
    """å¯åŠ¨ç©ºé—²ç›‘æ§çº¿ç¨‹"""
    global MONITOR_THREAD
    MONITOR_THREAD = threading.Thread(target=monitor_idle, daemon=True)
    MONITOR_THREAD.start()
    print(f"ğŸ” ç©ºé—²ç›‘æ§å·²å¯åŠ¨ï¼ˆ{IDLE_TIMEOUT // 60}åˆ†é’Ÿåè‡ªåŠ¨å…³é—­ï¼‰")


def main():
    parser = argparse.ArgumentParser(description='FunASR è½¬å½•æœåŠ¡ (FastAPI)')
    parser.add_argument('--port', type=int, default=8765, help='æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ 8765ï¼‰')
    parser.add_argument('--host', type=str, default='127.0.0.1', help='ç›‘å¬åœ°å€ï¼ˆé»˜è®¤ 127.0.0.1ï¼‰')
    parser.add_argument('--idle-timeout', type=int, default=600, help='ç©ºé—²è¶…æ—¶æ—¶é—´ï¼Œå•ä½ç§’ï¼ˆé»˜è®¤ 600ç§’=10åˆ†é’Ÿï¼‰')
    parser.add_argument('--preload', action='store_true', help='é¢„åŠ è½½æ¨¡å‹')
    args = parser.parse_args()

    # è®¾ç½®ç©ºé—²è¶…æ—¶
    global IDLE_TIMEOUT
    IDLE_TIMEOUT = args.idle_timeout

    if args.preload:
        init_model()

    # å¯åŠ¨ç©ºé—²ç›‘æ§
    start_idle_monitor()

    print(f"ğŸ™ï¸ FunASR è½¬å½•æœåŠ¡å¯åŠ¨ä¸­...")
    print(f"ğŸ“ åœ°å€: http://{args.host}:{args.port}")
    print(f"ğŸ“š API æ–‡æ¡£: http://{args.host}:{args.port}/docs")
    print(f"ğŸ” ç©ºé—²ç›‘æ§: {IDLE_TIMEOUT // 60}åˆ†é’Ÿè‡ªåŠ¨å…³é—­")
    print(f"ğŸ“‹ API ç«¯ç‚¹:")
    print(f"   POST /transcribe      - è½¬å½•å•ä¸ªæ–‡ä»¶")
    print(f"   POST /batch_transcribe - æ‰¹é‡è½¬å½•")
    print(f"   GET  /health          - å¥åº·æ£€æŸ¥\n")

    # å¯¼å…¥ uvicornï¼ˆå»¶è¿Ÿå¯¼å…¥ä»¥åŠ å¿«å¯åŠ¨é€Ÿåº¦ï¼‰
    import uvicorn
    uvicorn.run(app, host=args.host, port=args.port, log_level="info")


if __name__ == '__main__':
    main()
